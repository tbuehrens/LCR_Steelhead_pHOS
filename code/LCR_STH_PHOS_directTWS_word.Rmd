---
title: 'Estimates of Lower Columbia steelhead pHOS: Report to NOAA Fisheries'
author: Thomas Buehrens (thomas.buehrens@dfw.wa.gov),  Jeremy Wilson (Jeremy.Wilson@dfw.wa.gov), Steve Gray (steven.gray@dfw.wa.gov), and Jim Scott (jim.scott@dfw.wa.gov)
output:
  word_document:
always_allow_html: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../results") })
---
<script>
   $(document).ready(function() {
     $head = $('#header');
     $head.prepend('<img src=\"https://privatelands.wdfw.wa.gov/wdfwlogo_clrnotxt.png"\" style=\"float: right;width: 150px;\"/>')
   });
</script>

***

Last Updated `r format(Sys.time(), '%m/%d/%Y')`.

***

<!-- ## Overview-->
<!-- This markdown documents the estimation of pHOS for Lower Columbia winter steelhead populations based on spawning ground surveys. It is only completed for populations below dams and excludes the Lower Cowlitz & NF Lewis for which estimates are developed as part of other reporting processes. Estimates for Kalama and NF Toutle/Mainstem Toutle Populations are incomplete here because a portion of these populations is located above dams so these estimates must be combined with the above dam estimates for those populations. Summer steelhead pHOS estimates are also excluded because those are available from snorkel surveys. Three models are used to estimate pHOS: 1) method of moments where pHOS is calculated as (HOS/(HOS + NOS)) annually for each population in years data are available, 2) a multivariate state-space model fit to the count data using a logit link function and a binomial response using STAN [**rstan**](https://mc-stan.org/users/interfaces/rstan), 3) a Generalize Additive Model fit to the count data using a logit link function and a binomial response where a thin plate spline is fit independently to each population's data using the R package [**mgcv**](https://cran.r-project.org/web/packages/mgcv/mgcv.pdf). The model used to fit the logit-normal random walk is printed below in the appendix. -->

```{r set_options, echo = FALSE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
```


<!-- We also need a couple of helper functions which we will define -->
```{r load_funcs, message = FALSE, warning = FALSE,results = "hide",echo=FALSE}
#function
select_table_PostgreSQL<-function(database_args,SQL){
  con <- DBI::dbConnect(
    odbc::odbc(),
    Driver = database_args$Driver,
    Server = database_args$Server,
    Database = database_args$Database,
    Port = database_args$Port,
    UID = database_args$UID,
    PWD = database_args$PWD,
    Trusted_Connection = database_args$Trusted_Connection
  )
  dat<- data.frame(DBI::dbGetQuery(con, SQL))
  DBI::dbDisconnect(con)
  return(dat)
}

#function to add prediction to model output
add_predictions <- function (data, model, var = "pred", ...) {
     fit <- as_tibble(stats::predict(model, data, ...))
     names(fit)[1] <- var  
     bind_cols(data, fit)
}

#function to install or load packages
install_or_load_pack <- function(pack){
  create.pkg <- pack[!(pack %in% installed.packages()[, "Package"])]
  if (length(create.pkg))
    install.packages(create.pkg, dependencies = TRUE,repos = "http://cran.us.r-project.org")
  sapply(pack, require, character.only = TRUE)
}

#function for inverse logit transform.
ilogit<-function(x){exp(x)/(1+exp(x))}
```

<!-- Here we will load & install packages we need to use (needs internet connection if packages not already installed) -->
```{r load_packages, message = FALSE, warning = FALSE,results = "hide", echo=FALSE}
packages_list<-c("dataRetrieval"
                 ,"scales"
                 ,"RColorBrewer"
                 ,'viridis'
                 ,'ggsci'
                 ,'tidyverse'
                 ,'dplyr'
                 ,'readr'
                 ,'ggplot2'
                 ,'lubridate'
                 ,"mgcv"
                 ,"modelr"
                 ,"brms"
                 ,"kableExtra"
                 ,"rstan"
                 ,"reshape2"
                 ,"DBI"
                 ,"flextable"
                 ,"janitor"
                 )
install_or_load_pack(pack = packages_list)
```

<!-- ## User inputs -->
```{r user inputs, message = FALSE, warning = FALSE,results = "hide",echo=FALSE}
include_holders = T
```


<!-- ## Get Raw Data -->
<!-- In this section, data used in the analysis is loaded and prepared for analysis -->
```{r get_data, message=FALSE, warning=FALSE, results="show", echo=FALSE}
database_args<-list(
  Driver = "PostgreSQL Unicode",
  Server = Sys.getenv("POSTGRES_TWS_IP"),
  Database = "FISH",
  Port = 5433,
  UID = Sys.getenv("POSTGRES_TWS_UN"),
  PWD = Sys.getenv("POSTGRES_TWS_PW"),
  Trusted_Connection = "True"
)

SQL1<-
"SELECT 
  tws.HEADER.Survey_Date AS Date,
  tws.GEAR_LUT.gear,
  tws.SGS_REACHES_LUT.thomas_subpopulation AS Population,
  tws.sgs_reaches_lut.stream_name AS Stream,
  tws.sgs_reaches_lut.stream_reach_code AS Stream_Reach,
  tws.SGS_REACHES_LUT.upper_river_mile_meas AS Upper_RM,
  tws.SGS_REACHES_LUT.lower_river_mile_meas AS Lower_RM,
  splut.species AS species,
  runlut.run_desc AS Run,
  mlut.markcode AS Mark,
  'Live' AS Live_Carc,
  dclut.categorycode AS Live_Type,
  Sum(tws.DATASHEET_STREAM_SURVEY.Count_Num) AS Count 
FROM 
  tws.SGS_REACHES_LUT INNER JOIN (tws.HEADER INNER JOIN tws.DATASHEET_STREAM_SURVEY ON tws.HEADER.HEADER_Id = tws.DATASHEET_STREAM_SURVEY.HEADER_Id) ON tws.SGS_REACHES_LUT.stream_reach_id = tws.HEADER.STREAM_REACH_Id
  JOIN tws.species_lut splut ON tws.DATASHEET_STREAM_SURVEY.SPECIES_Id = splut.species_lut_id
  JOIN tws.run_lut runlut ON tws.DATASHEET_STREAM_SURVEY.RUN_LUT_Id = runlut.run_lut_id
  JOIN tws.mark_type_lut mlut ON tws.DATASHEET_STREAM_SURVEY.MARK_TYPE_LUT_Id = mlut.mark_type_id
  JOIN tws.datasheet_category_lut dclut ON tws.DATASHEET_STREAM_SURVEY.DatasheetCategory = dclut.datasheet_category_id
  JOIN tws.GEAR_LUT ON tws.HEADER.GEAR_TYPE_LUT_Id = tws.GEAR_LUT.gear_lut_id
GROUP BY 
  tws.HEADER.Survey_Date,
  tws.GEAR_LUT.gear,
  tws.SGS_REACHES_LUT.thomas_subpopulation, 
  tws.sgs_reaches_lut.stream_name, 
  tws.sgs_reaches_lut.stream_reach_code, 
  tws.SGS_REACHES_LUT.upper_river_mile_meas,
  tws.SGS_REACHES_LUT.lower_river_mile_meas, 
  splut.species,
  runlut.run_desc,
  mlut.markcode,
  Live_Carc, 
  dclut.categorycode
HAVING (((splut.species)='Steelhead'));"


dat1<-select_table_PostgreSQL(database_args=database_args,SQL=SQL1)%>%
     as_tibble()
SQL2<-
"SELECT
  tws.HEADER.Survey_Date AS Date,
  tws.GEAR_LUT.gear,
  tws.SGS_REACHES_LUT.thomas_subpopulation AS Population,
  tws.SGS_REACHES_LUT.stream_name AS Stream,
  tws.sgs_reaches_lut.stream_reach_code AS Stream_Reach,
  tws.SGS_REACHES_LUT.upper_river_mile_meas AS Upper_RM,
  tws.SGS_REACHES_LUT.lower_river_mile_meas AS Lower_RM,
  splut.species AS species,
  runlut.run_desc AS Run,
  mlut.markcode AS Mark,
  'Carc' AS Live_Carc, 
  '' AS Live_Type,
  COUNT(tws.SCALECARD_FRONT.SCALE_CARD_FRONT_Id) AS Count
FROM ((tws.SGS_REACHES_LUT INNER JOIN tws.HEADER ON tws.SGS_REACHES_LUT.stream_reach_id =      
  tws.HEADER.STREAM_REACH_Id) INNER JOIN tws.SCALECARD_BACK ON tws.HEADER.HEADER_Id = tws.SCALECARD_BACK.HEADER_Id) 
  INNER JOIN tws.SCALECARD_FRONT ON tws.SCALECARD_BACK.SCALE_CARD_Id = tws.SCALECARD_FRONT.SCALE_CARD_Id
  JOIN tws.species_lut splut ON tws.SCALECARD_BACK.SPECIES_Id = splut.species_lut_id
  JOIN tws.run_lut runlut ON tws.SCALECARD_BACK.RUN_LUT_Id = runlut.run_lut_id
  JOIN tws.mark_type_lut mlut ON tws.SCALECARD_FRONT.MARK_TYPE_LUT_Id = mlut.mark_type_id
  JOIN tws.GEAR_LUT ON tws.HEADER.GEAR_TYPE_LUT_Id = tws.GEAR_LUT.gear_lut_id
GROUP BY 
  tws.HEADER.Survey_Date,
  tws.GEAR_LUT.gear,
  tws.SGS_REACHES_LUT.thomas_subpopulation,
  tws.SGS_REACHES_LUT.stream_name,
  tws.sgs_reaches_lut.stream_reach_code, 
  tws.SGS_REACHES_LUT.upper_river_mile_meas,
  tws.SGS_REACHES_LUT.lower_river_mile_meas,
  splut.species,
  runlut.run_desc,
  mlut.markcode,
  Live_Carc,
  Live_Type,
  tws.HEADER.GEAR_TYPE_LUT_Id
HAVING ((splut.species='Steelhead') AND ((tws.gear_lut.gear)='Stream Survey' Or   
  (tws.gear_lut.gear)='IMW'));"



DF<-select_table_PostgreSQL(database_args=database_args,SQL=SQL2)%>%
     as_tibble()%>%
     bind_rows(dat1)%>%
     mutate(live_type=ifelse(live_type=="",NA,live_type),
            gear = ifelse(gear=="IMW","Stream Survey",gear)
            )


if(include_holders == F){
  DF<-DF%>%
       dplyr::filter(is.na(live_type) | live_type !="Holder") #can exclude holders (because could include live fish prior to harvest or recruitment to hatchery)...that said doesn't seem to change results 
  holders <-"no_holders"
}else{
  holders <-"with_holders"   
}  
DF<-DF%>%
  dplyr::filter(mark%in%c("LV","AD+LV","AD+RV","UM","AD"))%>%
  mutate(mark = ifelse(mark %in% c("AD","LV","AD+LV","AD+RV"),"HOS","NOS"))%>%
  dplyr::filter(population!="Cedar",
               population!="Delameter_Above Weir",
               population!="Salmon Creek",
               population!="White Salmon",
               population!="Olequa_Above Weir",
               population!="Ostrander_Above Weir",
               population!="Mainstem Columbia",
               population!="Lower Cowlitz",
               population!="")%>%
  mutate(population = str_replace(population, "Kalama","Kalama_below_KFH"),
        population = str_replace(population, "Green","NF_Toutle_Green_only")
  )%>%
  dplyr::mutate(date=ymd(date),
               year=year(date),
               month= month(date),
               spawn_year= ifelse(month < 12, year, year + 1)
  )%>%
  dplyr::filter(month >11 | month <7)%>% #exclude data from 6/30 -12/1 each year
  #dplyr::filter(spawn_year!="2023")%>% #not a complete year yet
  dplyr::group_by(spawn_year,population,mark,gear)%>%
  dplyr::summarise(count = sum(count))%>%
  pivot_wider(names_from = mark, values_from = count,values_fill = 0)%>%
  dplyr::mutate(pHOS_mom = HOS/(HOS+NOS),population=factor(population))%>% # calculate a "method of moments" estimate
  mutate(population = paste0(population," ","winter")) 
```

```{r get summer steelhead pHOS raw data,  message=FALSE, warning=FALSE, results="show", echo=FALSE}
SQLstring<-"
SELECT
  tws.header.header_id,
  tws.GEAR_LUT.gear,
  tws.header.survey_date,
  tws.header.return_yr,
  tws.header.gear_type_lut_id,
  tws.stream_name_lut.stream_name,
  tws.header.stream_reach_id,
  tws.species_lut.species,
  tws.datasheet_trap.mark_type_lut_id,
  tws.mark_type_lut.markcode,
  tag_type1.tag_type ,
  tag_color1.description,
  tag_type2.tag_type ,
  tag_color2.description,
  tws.datasheet_trap.count_num,
  tws.run_lut.run_desc
FROM
  (
    (
      tws.stream_name_lut
      LEFT JOIN (
        tws.header
        INNER JOIN tws.datasheet_trap ON tws.header.header_id = tws.datasheet_trap.header_id
      ) ON tws.stream_name_lut.stream_lut_id = tws.header.stream_lut_id
    )
    LEFT JOIN tws.species_lut ON tws.datasheet_trap.species_id = tws.species_lut.species_lut_id
  )
  LEFT JOIN tws.mark_type_lut ON tws.datasheet_trap.mark_type_lut_id = tws.mark_type_lut.mark_type_id
  LEFT JOIN tws.run_lut ON tws.datasheet_trap.run_lut_id = tws.run_lut.run_lut_id
  LEFT JOIN tws.tag_type_lut AS tag_type1 ON tws.datasheet_trap.recapture_tag_1_type_lut_id = tag_type1.tag_type_lut_id
  LEFT JOIN tws.tag_shape_color_lut AS tag_color1 ON tws.datasheet_trap.recapture_tag_1_shape_color_type_lut_id = tag_color1.tag_shape_color_lut_id
  LEFT JOIN tws.tag_type_lut AS tag_type2 ON tws.datasheet_trap.recapture_tag_2_type_lut_id = tag_type2.tag_type_lut_id 
  LEFT JOIN tws.tag_shape_color_lut AS tag_color2 ON tws.datasheet_trap.recapture_tag_2_shape_color_type_lut_id = tag_color2.tag_shape_color_lut_id
  JOIN tws.GEAR_LUT ON tws.HEADER.GEAR_TYPE_LUT_Id = tws.GEAR_LUT.gear_lut_id
WHERE
  (
    ((tws.GEAR_LUT.gear) = 'Snorkel Survey')
    AND ((tws.species_lut.species) = 'Steelhead')
    AND ((tws.run_lut.run_desc) = 'Summer')
  )
  OR (
    ((tws.GEAR_LUT.gear) = 'Snorkel Survey')
    AND ((tws.species_lut.species) = 'Steelhead')
    AND ((tws.run_lut.run_desc) = 'Summer')
  );
"

DF<-DF%>%
  bind_rows(
    select_table_PostgreSQL(database_args=database_args,SQL=SQLstring)%>%
    as_tibble()%>%
    filter(stream_name %in%c("Washougal River","Lewis River - East Fork","Kalama River", "Wind River"))%>% 
    mutate(population=paste0(stream_name," ",str_to_lower(run_desc)))%>%
    mutate(spawn_year=ifelse(month(survey_date)>4,year(survey_date)+1,year(survey_date)))%>%
    group_by(population,spawn_year,markcode,gear)%>%
    summarise(count_num=sum(count_num))%>%
    filter(markcode%in%c("UM","AD"))%>%
    mutate(markcode = ifelse(markcode=="AD","HOS","NOS"))%>%
    pivot_wider(id_cols=c("spawn_year","population"),names_from = markcode,values_from = count_num)%>%
    mutate(HOS=as.integer(ifelse(is.na(HOS),0,HOS)),
           NOS=as.integer(ifelse(is.na(NOS),0,NOS)
                          )
    )%>%
    mutate(pHOS_mom = (HOS/(HOS+NOS)))
  )%>%
  arrange(population,spawn_year)%>%
  ungroup()%>%
  mutate(
    population=str_remove_all(population, "[[:punct:]]"),
    pop_ind=as.numeric(as.factor(population))
    )
```

<!-- ## Analysis & Results -->
<!-- In this section we estimate annual pHOS by population with the clip status data using Generalized Additive Models and then present the results in graphical and tablular form. -->
```{r Analysis_v1, message=FALSE, warning=FALSE, results="show", echo=FALSE}
stan_dat<-list(
     T = length(min(DF$spawn_year):max(DF$spawn_year)),
     T_forward = 0,
     T_backward = 0,
     P = length(unique(DF$population)),
     n = dim(DF)[1],
     HOS_obs = as.integer(DF$HOS),
     NOS_obs = as.integer(DF$NOS),
     pop_obs = DF$pop_ind,
     year_obs = DF$spawn_year-min(DF$spawn_year) + 1
)
if(!file.exists(here::here("code/stan_model.rds"))){
     model<-stan_model(here::here("code/binomial_ss_random_walk_model_mv.stan"))
     saveRDS(model,here::here("code/stan_model.rds"))
}else{
     model<-readRDS(here::here("code/stan_model.rds"))
}
if(!file.exists(here::here(paste0("results/stan_fit_",holders,".rds")))){
m1_stan<-sampling(
     object = model,
     data = stan_dat,
     chains = 4,
     cores = 4,
     iter = 2000,
     warmup = 1000,
     thin = 1
)
saveRDS(m1_stan,here::here(paste0("results/stan_fit_",holders,".rds")))
}else{
     m1_stan<-readRDS(here::here(paste0("results/stan_fit_",holders,".rds")))
}


results<-extract(m1_stan)
DF<-data.frame(reshape2::melt(results$p_all))%>%
  as_tibble()%>%
  dplyr::rename(spawn_year = Var2,
           pop_ind = Var3
           )%>%
  mutate(spawn_year = spawn_year + min(DF$spawn_year) - 1)%>%
  left_join(DF%>%
             group_by(population)%>%
             summarise(population = first(population), pop_ind = first(pop_ind))
           )%>%
  dplyr::select(-pop_ind)%>%
  group_by(population,spawn_year)%>%
  summarise(value = quantile(value, c(0.025,0.5,0.975)), q = c(0.025, 0.5,0.975))%>%
  pivot_wider(names_from = q,values_from = value)%>%
  dplyr::rename(pHOS_ss_rw = `0.5`,
               pHOS_ss_rw_lower = `0.025`,
               pHOS_ss_rw_upper = `0.975`
               )%>%
  left_join(DF%>%dplyr::select(-pop_ind),by=c("spawn_year","population"))%>%
  ungroup()%>%
  arrange(population, spawn_year)
  
```

```{r Analysis_v2, message=FALSE, warning=FALSE, results="show", echo=FALSE}
m1<-gam(cbind(as.integer(HOS),as.integer(NOS)) ~ s(spawn_year,by=factor(population),bs="bs",m=1,k=-1), family = "binomial",data=DF)

DF<-expand.grid("population" = unique(DF$population),
                    "spawn_year" = unique(DF$spawn_year)
                    )%>%
     as_tibble()%>%
     add_predictions(m1,type="link", var ="pHOS_gam",se.fit=T)%>%
     mutate(pHOS_gam_lower = ilogit(pHOS_gam - 1.96 * se.fit),
            pHOS_gam_upper =ilogit(pHOS_gam + 1.96 * se.fit),
            pHOS_gam=ilogit(pHOS_gam)
            )%>%
     left_join(DF,by=c("spawn_year","population"))%>%
     ungroup()%>%
     arrange(population, spawn_year)
```

```{r abundance weighted avg, message=FALSE, warning=FALSE, results="show", echo=FALSE}
database_args<-list(
    Driver = "PostgreSQL Unicode",
    Server = Sys.getenv("POSTGRES_SPI_IP"),
    Database = "FISH",
    Port = 5433,
    UID = Sys.getenv("POSTGRES_SPI_UN"),
    PWD = Sys.getenv("POSTGRES_SPI_PW"),
    Trusted_Connection = "True"
    )

SPIdat<-select_table_PostgreSQL(database_args=database_args,SQL="SELECT * FROM spi.vw_ca_nosa_sos;")%>%
  filter(SASISTOCKNAME %in% c("Kalama Winter Steelhead","North Fork Toutle Winter Steelhead"))

lowertoutleprop<-SPIdat%>%
  filter(POPFITNOTES=="Green River Tributary index only - not a total population estimate" |
         POPFITNOTES=="Total Escapement Estimate MS and Trib Surveys and NFT FCF Trap Counts"  
           )%>%
  mutate(subpop=ifelse(grepl("Green",POPFITNOTES),"NF_Toutle_Green_only","NF_Toutle_Total"))%>%
  dplyr::select(SPAWNINGYEAR,SASISTOCKNAME,subpop,tsaej)%>%
  pivot_wider(names_from = subpop,values_from = tsaej)%>%
  filter(!is.na(NF_Toutle_Green_only) & !is.na(NF_Toutle_Total))%>%
  mutate(p_NF_Toutle_Green_only = NF_Toutle_Green_only/NF_Toutle_Total)


AppendixTable1<-lowertoutleprop%>%
  mutate(p_NF_Toutle_Green_only = scales::percent(p_NF_Toutle_Green_only, accuracy=0.1),
         SPAWNINGYEAR=as.character(SPAWNINGYEAR)
         )%>%
  dplyr::rename(spawn_year=SPAWNINGYEAR)%>%
  flextable() %>% 
  align(part = "all") %>% # left align
  set_caption(caption = 'Appendix Table 1. The number and proportion of total spawners in two subpopulation areas of the NF Toutle: 1) the Green River and tributaries below the Toutle Sediment Retention Structure (SRS), and 2) The entire NF Toutle including areas above and below the SRS' , align_with_table = F) %>% 
  font(fontname = "Calibri (Body)", part = "all") %>% 
  fontsize(size = 6, part = "body") %>% 
  theme_booktabs() %>% # default theme
  autofit()

NF_Toutle_winter_total <- lowertoutleprop %>%
  dplyr::select(spawn_year = SPAWNINGYEAR, p_NF_Toutle_Green_only) %>%
  mutate(population = "NFToutleGreenonly winter") %>%
  left_join(DF) %>%
  mutate(across(c("pHOS_gam",
                  "pHOS_gam_lower",
                  "pHOS_gam_upper",
                  "pHOS_ss_rw_lower",
                  "pHOS_ss_rw",
                  "pHOS_ss_rw_upper",
                  "pHOS_mom"
                  ), ~ . * p_NF_Toutle_Green_only
  ))%>%
  mutate(HOS=NA,NOS=NA,gear="spawning ground survey and trap",se.fit=NA)%>%
  dplyr::select(-p_NF_Toutle_Green_only)%>%
  mutate(population="NF_Toutle winter")

upperkalamaprop<-SPIdat%>%
  filter(POPFIT=="Same"|
         POPFITNOTES=="Above KFH only." & METHODNUMBER ==1
           )%>%
  mutate(subpop=ifelse(grepl("Above",POPFITNOTES),"Kalama_above_KFH","Kalama_winter_total"))%>%
  dplyr::select(SPAWNINGYEAR,SASISTOCKNAME,subpop,tsaej)%>%
  pivot_wider(names_from = subpop,values_from = tsaej)%>%
  filter(!is.na(Kalama_above_KFH) & !is.na(Kalama_winter_total))%>%
  mutate(p_Kalama_above_KFH_only = Kalama_above_KFH/Kalama_winter_total)


AppendixTable2<-upperkalamaprop%>%
  mutate(p_Kalama_above_KFH_only = scales::percent(p_Kalama_above_KFH_only, accuracy=0.1),
         SPAWNINGYEAR=as.character(SPAWNINGYEAR)
         )%>%
  dplyr::rename(spawn_year=SPAWNINGYEAR)%>%
  flextable() %>% 
  align(part = "all") %>% # left align
  set_caption(caption = 'Appendix Table 2. The number and proportion of total winter steelhead spawners in two subpopulation areas of the Kalama River: 1) the upper Kalama above Kalama Falls Hatchery, and 2) The entire Kalama River including areas above and below KFH' , align_with_table = F) %>% 
  font(fontname = "Calibri (Body)", part = "all") %>% 
  fontsize(size = 6, part = "body") %>% 
  theme_booktabs() %>% # default theme
  autofit()


Kalama_winter_total <- upperkalamaprop %>%
  dplyr::select(spawn_year = SPAWNINGYEAR, p_Kalama_above_KFH_only) %>%
  mutate(population = "KalamabelowKFH winter") %>%
  left_join(DF) %>%
  mutate(across(c("pHOS_gam",
                  "pHOS_gam_lower",
                  "pHOS_gam_upper",
                  "pHOS_ss_rw_lower",
                  "pHOS_ss_rw",
                  "pHOS_ss_rw_upper",
                  "pHOS_mom"
                  ), ~ . * (1-p_Kalama_above_KFH_only)
  ))%>%
  mutate(HOS=NA,NOS=NA,gear="spawning ground survey and trap",se.fit=NA)%>%
  dplyr::select(-p_Kalama_above_KFH_only)%>%
  mutate(population="Kalama winter")


DF<-DF%>%
  bind_rows(NF_Toutle_winter_total)%>%
  bind_rows(Kalama_winter_total)

```


```{r Predictions_ss_rw, message=FALSE, warning=FALSE, results="show", echo=FALSE}
p1<-ggplot(DF%>%filter(spawn_year>2010),aes(x=spawn_year,y=pHOS_ss_rw,group=population))+
     geom_ribbon(aes(ymin=pHOS_ss_rw_lower,ymax=pHOS_ss_rw_upper),color=NA,fill="black",alpha=0.5)+
     geom_line(size=0.6)+
     geom_point(aes(y=pHOS_mom,size=as.numeric(HOS+NOS)))+
     scale_size(name   = "Sample Size",
                breaks = c(2,4,8,16,32,64,128,256),
                labels = c(2,4,8,16,32,64,128,256)
                )+
     facet_wrap(~population,ncol=2)+
     ylab("Proportion of Hatchery-Origin Spawners")+
     xlab("Spawn Year")+
     theme_bw()+
     theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
  ggsave(here::here("results/p1.png"), width = 8, height = 10, units = "in", dpi = 300)
```

```{r Predictions_gam, message=FALSE, warning=FALSE, results="show", echo=FALSE}
p2<-ggplot(DF%>%filter(spawn_year>2010),aes(x=spawn_year,y=pHOS_gam,group=population))+
     geom_ribbon(aes(ymin=pHOS_gam_lower,ymax=pHOS_gam_upper),color=NA,fill="black",alpha=0.5)+
     geom_line(size=0.6)+
     geom_point(aes(y=pHOS_mom,size=as.numeric(HOS+NOS)))+
     scale_size(name   = "Sample Size",
                breaks = c(2,4,8,16,32,64,128,256),
                labels = c(2,4,8,16,32,64,128,256)
                )+
     facet_wrap(~population,ncol=2)+
     ylab("Proportion of Hatchery-Origin Spawners")+
     xlab("Spawn Year")+
     theme_bw()+
     theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
  ggsave(here::here("results/p2.png"), width = 8, height = 10, units = "in", dpi = 300)
```


```{r tables, message=FALSE, warning=FALSE, results="show", echo=FALSE}
DF2<-DF%>%
     filter(spawn_year>year(Sys.Date())-5)%>%
     group_by(population)%>%
     summarise(mean_pHOS_ss_rw = scales::percent(mean(pHOS_ss_rw),accuracy = 0.1),
               mean_pHOS_mom = scales::percent(mean(pHOS_mom,na.rm=T),accuracy = 0.1),
               mean_pHOS_gam = scales::percent(mean(pHOS_gam),accuracy = 0.1))
               #min= scales::percent(min(pHOS_gam),accuracy = 0.1),
               #max=scales::percent(max(pHOS_gam),accuracy = 0.1))

write.csv(DF2,here::here(paste0("results/5_year_mean_pHOS_",holders,".csv")),row.names = F) 


Table1<-DF2%>%
  flextable() %>% 
  align(part = "all") %>% # left align
  set_caption(caption = 'Table 1. 5-year Mean pHOS by Population. Three estimates are provided: 1) results from the state space random walk model ("mean_pHOS_ss_rw"), 2) results from the GAM analysis ("mean_pHOS_gam"), and 3) 5 year means based on method of moment estimates ("mean_pHOS_mom") calculated independently each year: (HOS/(HOS + NOS))', align_with_table = F) %>% 
  font(fontname = "Calibri (Body)", part = "all") %>% 
  fontsize(size = 6, part = "body") %>% 
  # add footer if you want
  # add_footer_row(values = "* p < 0.05. ** p < 0.01. *** p < 0.001.", 
  #                colwidths = 4) %>% 
  theme_booktabs() %>% # default theme
  autofit()


DF3<-DF%>%
  mutate(pHOS_ss_rw = scales::percent(pHOS_ss_rw,accuracy = 0.1,na.rm=T),
         pHOS_ss_rw_lower = scales::percent(pHOS_ss_rw_lower,accuracy = 0.1,na.rm=T),
         pHOS_ss_rw_upper = scales::percent(pHOS_ss_rw_upper,accuracy = 0.1,na.rm=T),
         pHOS_gam = scales::percent(pHOS_gam,accuracy = 0.1,na.rm=T),
         pHOS_gam_lower = scales::percent(pHOS_gam_lower,accuracy = 0.1,na.rm=T),
         pHOS_gam_upper = scales::percent(pHOS_gam_upper,accuracy = 0.1,na.rm=T),
         pHOS_mom = scales::percent(pHOS_mom,accuracy = 0.1,na.rm=T)
         )%>%
  dplyr::select(-se.fit)%>%
  group_by(population) %>%
  slice(which(spawn_year >= min(spawn_year[!is.na(pHOS_mom)])))

# DF3%>%
#      kbl(caption = 'Table 2. Raw Data and PHOS estimates by year and population. Three estimates are provided: 1) results from the state space random walk model ("pHOS_ss_rw") and associate 95% CI, 2) results from the GAM analysis ("mean_pHOS_gam") and associate 95% CI, and 3) results of moment estimates ("mean_pHOS_mom") calculated independently each year: (HOS/(HOS + NOS))' ,digits =3)%>%
#      kable_classic(full_width = F, html_font = "Cambria")
write.csv(DF3,here::here(paste0("results/summarized_data_and_annual_pHOS_ests_",holders,".csv")),row.names = F)


AppendixTable3<-DF3%>%
  mutate(spawn_year=as.character(spawn_year))%>%
  flextable() %>% 
  align(part = "all") %>% # left align
  set_caption(caption = 'Appendix Table 3. Raw Data and PHOS estimates by year and population. Three estimates are provided: 1) results from the state space random walk model ("pHOS_ss_rw") and associate 95% CI, 2) results from the GAM analysis ("mean_pHOS_gam") and associate 95% CI, and 3) results of moment estimates ("mean_pHOS_mom") calculated independently each year: (HOS/(HOS + NOS))', align_with_table = F) %>% 
  font(fontname = "Calibri (Body)", part = "all") %>% 
  fontsize(size = 6, part = "body") %>% 
  # add footer if you want
  # add_footer_row(values = "* p < 0.05. ** p < 0.01. *** p < 0.001.", 
  #                colwidths = 4) %>% 
  theme_booktabs() %>% # default theme
  rotate(rotation = "tbrl",part='header')%>%
  autofit()
```

## Executive Summary
Hatchery steelhead provide valuable angling opportunities and can be used to supplement natural origin populations but may also pose risks to natural origin populations. As a result the proportion of hatchery origin spawners (pHOS) may be monitored as a measure of ecological and genetic interactions between hatchery origin and natural origin steelhead. We report estimates of pHOS for Lower Columbia winter and summer steelhead populations based on statistical smoothing models fit to observations of hatchery and natural origin spawners during spawning ground surveys (winter steelhead) and snorkel surveys (summer steelhead). Results currently exclude the Cowlitz and Lewis Basin populations for which estimates are developed as part of other reporting processes associated with dam operator licenses. Estimates for Kalama and NF Toutle winter run populations are reported both for below-dam sub-populations as well as the whole populations which are generated by developing spawner abundance-weighted averages of pHOS below the dams in these basins based on spawning ground surveys, with above-dam estimates generated with trap counts. Three models are used to estimate pHOS: 1) method of moments where pHOS is calculated annually as (HOS/(HOS + NOS)) for each population in years data are available, 2) a multivariate state-space model fit to the count data using a logit link function and a binomial response using STAN [**rstan**](https://mc-stan.org/users/interfaces/rstan), 3) a Generalized Additive Model fit to the count data using a logit link function and a binomial response where a thin plate spline is fit independently to each population's data using the R package [**mgcv**](https://cran.r-project.org/web/packages/mgcv/mgcv.pdf). The model used to fit the state-space logit-normal random walk is printed below in the appendix. 

## Introduction

## Methods

### Field Methods: Summer Steelhead Snorkel Surveys

Summer steelhead populations in the Wind, Kalama, and East Fork Lewis and Washougal Rivers are monitored using a Lincoln-Petersen mark-re-sight study design during which fish are captured and tagged, and re-sighted during snorkels. To accomplish this upstream migrating summer steelhead are captured, taggged, and released and are then available to be observed during subsequent snorkel re-sight efforts that enumerate tagged and untagged steelhead as well as adipose fin clip status. 

Tagging operations employ diverse methods to capture steelhead throughout the lower Columbia region. The preferred method is fish traps installed within permanent infrastructure at hatchery facilities and fish ladders but mobile in-situ efforts using large seine nets and hook-and-line angling are also used. Tagging of adult fish is completed from early May through September with a minimum annual goal of 100 fish tagged per population. Mobile seine net tagging involves the use of a 200 foot long by 12-foot high, small mesh (ca ¼ inch) cotton net to target and capture returning adults in areas where they naturally congregate. Hook and line angling uses common recreational fishing gear and the use of barbless hooks when practical. Terminal gear may be bait or artificial in nature. 

Operations within the Washougal basin historically used the mobile seine net operations through 2012. In 2013, hatchery infrastructure upgrades were completed and included the construction of an adult ladder with an integrated trapping structure which has become the primary means of collection and tagging subsequently. Tagging operations in the East Fork Lewis River have used the mobile seine net as a primary means of collection and tagging since the projects’ inception.  A secondary methodology is the use of hook-and-line.  Only twice has this been employed, 2015 and 2016, and was the result of low adult abundance that resulted in poor effectiveness of the preferred seine net. Netting efforts usually begin in late June or early July as a function of fish accumulations at known staging areas. Efforts will continue until the goal of 100 fish are tagged or snorkel operations are implemented.  All adult fish are transported using rubber knotless landing nets and handling is done without the aid of gloves.

Once captured, all adipose-intact fish are biologically sampled using an anesthetic water bath of Tricaine methane sulfonate, commonly known as Tricaine-S, TMS, or MS-222.  Concentration dosage is approximately 60 – 70 mg/L.  A buffer solution of sodium bicarbonate is also used at the same concentration dosage as the anesthesia.  Adipose-clipped fish are not anesthetized.  The following morphometric data is collected on every fish: species, run, gender, length, fin clips status, dorsal fin condition, other marks that may include marine mammal or other natural sources of injury.  Genetic material is taken from the caudal fin as well as six (6) scales for age composition analysis. External T-bar anchor tags, commonly known as Floy® Tags, are applied at the posterior end of the dorsal fin.  Different tag colors are applied on an annually rotating basis, fluorescent pink, combination orange/white, and combination fluorescent pink/blue.  Tags are sequentially numbered, and two tags are used per fish, one on each side of the dorsal fin.  Once tagged, fish are released back into the area where they were captured for recovery and distribution at their own volition.

Downstream snorkel surveys are used as the mark-resight method in September to count and categorize all steelhead observed within the study area(s). Snorkel reaches include all areas known to contain non-negligible numbers of holding summer steelhead in these watersheds. River basins are divided into sections and groups of 2-3 snorkelers are assigned to each section.  All snorkelers move downstream methodically together to observe and count all adult steelhead encountered.  Encountered steelhead are categorized as follows; untagged NOR, untagged HOR, at least 1 tag present NOR, double-tagged NOR, single tagged NOR, at least 1 tag present HOR, double tagged HOR, single tagged HOR, untagged unknown adipose presence, NOR unknown tag presence, HOR unknown tag presence, and unknown origin unknown tag presence.  Fish that have an unknown origin but tag presence was positively observed are assigned mathematically to the most likely group as a function of percentages observed. 

For all un-tagged steelhead, adipose fin clip status is recorded (clipped, intact, unknown), which provides a basis for estimating pHOS. Washougal, Wind,  EF Lewis snorkel areas have in almost all cases been closed to all fishing or at least to steelhead retention, so snorkel-based pHOS estimates do not need to be not corrected for harvest removals. In the Kalama, pHOS estimates from snorkels may be positively biased due to harvest of hatchery steelhead occurring between the September snorkel and spawning, although this harvest is generally limited and the bias is thought to be limited, particularly in recent years.


### Field Methods: Winter Steelhead Spawning Ground Surveys

Monitoring of Viable Salmon Population (VSP; McElhany 2000) parameters for winter steelhead in the Lower Columbia is accomplished predominately through spawning ground surveys. These surveys which occur in 13 watersheds, involve walking and rafting to observe, enumerate, and collect biological data from live and dead steelhead, and their redds. In a smaller number of watersheds resistance board weirs (Lower Cowlitz Tributaries) are used to collect biological data and Floy tag steelhead for Petersen mark-recapture experiments, or dam fish ladder traps (upper NF Toutle, Upper Cowlitz, Cispus, Tilton, and upper NF Lewis) are used to obtain a census count of spawners and collection biological data.

Surveys that are thought to approximate a spatially balanced sample of steelhead spawning areas occur from October through June. From October through January, surveys are salmon-focused but enumerate and sample steelhead and their redds encountered. The salmon focused surveys occur weekly and employ a spatial design including index surveys in lower basins and Generalized Random Tessellation-Stratified surveys in areas not covered by indexes, which together provide a substantially representative sample of reaches from the entirety of areas used by steelhead for spawning. From January to June, surveys switch reaches to a steelhead-focused study design. Survey sections were selected non-randomly and range from 0.1 – 10.0 miles in length and are categorized as index, supplemental, and exploratory.  Index sections are surveyed regularly with the intent to complete one survey every 21 days.  Supplemental surveys are additional areas of spawning outside the index areas that are only surveyed during the peak period of spawning which is typically April – May.  Exploratory sections are additional areas of interest outside the index and supplemental sections where spawning activity may be occurring but are only surveyed on an ad hoc basis as a function of time and personnel resources.  The beginning and end locations for each section are identified using blue and white striped surveyor flagging with the name of the section written on the flagging.

During each survey, staff walk or float to observe, and record live adult fish, redd presence, and any dead steelhead carcasses.  Adult live fish are categorized by species and then whether they are spawner or holder.  Spawner fish are those that, at the time of observation, are in area where spawnable habitat exists and spawning may occur; Holder fish are those that are observed in areas where spawnable habitat does not exist and spawning may not occur.  All completed redds that are encountered are recorded electronically and then identified with the use of pink surveyors’ flagging that represents their unique ID as well as an XY coordinate used to geolocate each unique redd relative to the flag itself.  All new maiden redds are recorded and identified individually for the duration of the survey season to prevent double counting.  New maiden redds must contain three criteria for it to be considered a redd: 1) color change from the surrounding substrate as evidence of some type of disturbance to the stream bed, 2) the presence of a depression in the substrate approximately 6-10 inches in depth that has been excavated as a result of the female steelhead moving rocks and debris with their tail; 3) the presence of a tailings pile downstream of the excavated depression.   Overall size of all three of these components should be approximately 3-4 feet in diameter at a minimum.  Structures or activity smaller than this should be evaluated for hydraulic activity, incomplete pre-spawn activity by steelhead, or spawning of other species such as pacific lamprey or resident trout.

Status of all redds on subsequent surveys is recorded as Still Visible (SV) or Not Visible (NV).  SV are those redds that are deemed to be still actively tended or used by adult steelhead for spawning purposes.  Characteristics include good color change still being present, minor presence of fine sediment buildup or detritus and debris in the depression, minor erosion of the edges of the depression creating a chamfer of what would normally be a sharp crisp edge to the depression.  Consider this, “if the flag was not already hung to identify it, would you deem it to be a new maiden redd?”; if YES, then it is SV.  Record the updated status of the redd electronically as well as on the original flagging material and move on.  NV are those redds that have lost their color change, significant erosion has occurred to eliminate the edges of the depression, and significant debris and sediment has settled into the depression.  Record the updated status of the redd electronically as well as on the original flagging and lastly, tie black and white striped surveyor flagging to the original pink flagging.  This serves as an easy visual identifier for the NV status of what was an active redd.  Leave all flagging in place until the end of the spawning season when it will be removed.  Lastly, some active or SV redds may become superimposed due the spawning activity of other fish.  When this occurs, the pre-existing redd will appear to have a half-moon shape as a result of the new depression being created which is just slightly offset from the original.  By default, this renders the pre-existing redd NV and the new activity, if all three characteristics are present, would then be recorded as a new maiden redd.

Data collection is done with the use of Apple iPads using software from iForms.  All observations and survey information regarding date, time, location, and sampler data is captured for each index, supplemental, or exploratory section.  All scale card bio- and morphometric data is also captured in the iPad; only the physical scale samples are housed on the hard copy scale card.

Any carcasses found are identified to species, run (summer or winter), and sampled for biologic and morphometric data.  Data collected include any opercula punches/marks/tags, fork length, gender, mark type, floy tag presence/absence, Coded Wire Tag status, DNA sample is taken, carcass condition (live, fresh, slight decay, decayed, very decayed, skeleton), and gill color.  Six scales are collected, and the tail is then cut off to visually ID the fish as having already been sampled on a previous survey which prevents double counting and sampling.

Live fish that are observed are classified as spawners (observed in shallow water and/or on redds) or holders (in deeper pools not on spawning habitat), are identified to species, and adipose fin clip status is recorded (clipped, intact, unknown). Like summer steelhead snorkel survey counts of adipose clipped and intact steelhead, counts of live and dead winter steelhead by clip status may used to estimate pHOS.


### Analytical Methods
The proportion of hatchery origin spawners $pHOS$ may be estimated by dividing the total abundance of hatchery origin spawners $HOS$ by the total spawner abundance $TOS$. However, origin (hatchery or natural) is frequently unknown for the majority of the population and instead only a sample is available. Assuming simple random sampling, $pHOS$ may be estimated using a binomial distribution from a subsample of the population where origin is known:

$${HOS} \sim binomial({TOS}, {pHOS})$$
A maximum likelihood estimate (MLE) may be obtained using the method of moments as:
$$\hat{pHOS} = \frac {HOS} {{HOS} + {NOS}}$$
This estimator is asymptotically unbiased and provides a good estimate of $pHOS$ with sufficient sample sizes. However, for populations lacking efficient capture locations like dams and fish ladders, observations of live and dead spawners permitting the identification of origin may be severely limited with very small sample sizes and some years with no observations. This results in very "noisy" estimates of $pHOS$ using the MLE and binomial estimators above. 

However, if one has multiple years of data and/or multiple populations, estimates of $pHOS$ may be improved by using estimators that exploit the non-independence of consecutive annual datasets (e.g., that composition of spawers may be correlated over time, facilitating temporal smoothing models). We employed two such estimators. 

First we used a multivariate state space random walk, fit with a logit link function, where pHOS followed the follow process model:

$${pHOS}_{t,1:p} = ilogit(logit({pHOS}_{t-1,1:p}) + {\epsilon}_{t,1:p})$$
Where process errors ${\epsilon}$ are estimated as:

$${\epsilon}_{t,1:p} \sim MVN(0,\Sigma)$$
And $\Sigma$ is decomposed via LDL Cholesky decomposition into a lower left triangular correlation matrix $L$ containing among-population correlations in process errors, and a diagonal matrix consisting of the population specific process error standard deviations ${\sigma}_{p}$.

The likelihood was given by:
$${HOS}_{t,p} \sim binomial({TOS}_{t,p}, {pHOS}_{t,p})$$

The model was estimated in a Bayesian framework using [**Rstan**](https://mc-stan.org/users/interfaces/rstan) and thus the following priors were used.

The population-specific process error standard deviations were estimated hierarchically with an among population mean ${\sigma}_{mu}$ and unit-normal population-specific random effects ${\gamma}_{p}$ which were scaled by multiplication with the among-population standard deviation in process error standard deviations ${\sigma}_{\sigma}$.
$${\sigma}_{p} = e^{log({\sigma}_{mu}) + {\gamma}_{p}{\sigma}_{\sigma}}$$
The lower left triangular correlation matrix was given a Lewandowski-Kurowicka-Joe (LKJ) distribution with one degree of freedom:
$$L \sim LKJ(1)$$
The among population mean process error standard deviation ${\sigma}_{mu}$ was given a half unit-normal prior:
$${\sigma}_{mu} \sim N(0,1) [0,{\infty}]$$
and the among population standard deviation in process error standard deviations was given a half unit-normal prior:
$${\sigma}_{\sigma} \sim N(0,1) [0,{\infty}]$$

Finally, to initialize the process model, the first state was given an uninformative flat prior:
$${pHOS}_{t=1,1:p} \sim beta(1,1)$$
The complete model code is reprinted below in Appendix 3.

We also fit a Generalized Additive Model using the mgcv [**package**](https://cran.r-project.org/web/packages/mgcv/index.html). In this case we used the same binomial likelihood for the response variable as in the state-space approach:
$${HOS}_{t,p} \sim binomial({TOS}_{t,p}, {pHOS}_{t,p})$$
but the predictions on the logit link scale were estimated using a spline on spawn year:
$${pHOS}_{t,p} = ilogit(s(year, by = p, k = 4, m = 1, bs = ps))$$
where $s$ is the operator for the spline, by $p$ indicates the independent fitting of the splines for each population, and $k$ indicates the number of knots where -1 indicates that the number of knots for the spline will be chosen automatically by Generalized Cross-validation (GCV), and $bs$ is the spline basis function type which was set to basis splines, and $m$ is the penalty order which was set to 1 for first order smoothing.

### Weighting subpopulation estimates to obtain population estimates of pHOS

For the Kalama and NF Toutle populations, spawning ground surveys only cover a portion of the spawning habitat, wheres dam trap counts provide a census count of the remainder of spawners (above Kalama Falls and the Toutle SRS). To obtain population estimates, pHOS below the traps, from spawning ground surveys is combined via and abundance-weighted average with pHOS above the traps, which is zero due to the management choice not to put Winter hatchery steelhead upstream in both basins. For the NF Toutle winter steelhead population, pHOS above the SRS is zero. Therefore we calculated the total proportion of spawners that occurred above and below the SRS based on annual abundance estimates for the two areas reported in WDFW's Salmon Population Indicators [**(SPI)**](https://data.wa.gov/Natural-Resources-Environment/WDFW-Salmonid-Population-Indicators-SPI-Escapement/fgyz-n3uk) database in each year and multiplied those proportions (Table 2) by the annual pHOS estimates for the sub-population below the SRS (Table 3) to obtain a weighted average for each year. The same approach was used for the Kalama River where pHOS was zero above Kalama falls for winter steelhead, and the pHOS below Kalama Falls Hatchery was mulitplied by the proportion of total spawners below the hatchery to obtain a population level estimate of pHOS. Over many years an average of 10% of Kalama winter steelhead spawn below the falls (Jeremy Wilson, WDFW, unpublished data) so this percent was used to weight all years.

## Results

### pHOS estimates from the state space random walk model

Figure 1 shows the annual pHOS estimates for each population (or subpopulation for Kalama below KFH and NF Toutle Green only) based on the state space random walk model with method of moment estimates plotted for comparison.
```{r plot_ss_rw, fig.height=10, fig.width=8, message=FALSE, warning=FALSE, results="show",fig.cap="Figure 1. Estimates of pHOS for Lower Columbia Winter Steelhead by population and year. Method of moment estimates (HOS/(HOS + NOS)) are shown as points where size corresponds to sample size. Estimates from the state-space multivariate random walk model using a logit link with a binomial response are shown as a posterior median (line) and 95% CI (shading).", echo=FALSE,out.width = '100%'}
print(p1)
```

Figure 2 shows the annual pHOS estimates for each population (or sub-population for Kalama below KFH and NF Toutle Green only) based on the GAM model with method of moment estimates plotted for comparison.
```{r plot_gam, fig.height=10, fig.width=8, message=FALSE, warning=FALSE, results="show",fig.cap="Figure 2. Estimates of pHOS for Lower Columbia Winter Steelhead by population and year. Method of moment estimates (HOS/(HOS + NOS)) are shown as points where size corresponds to sample size. GAM estimates are shown as an MLE (line) and 95% CI (shading).", echo=FALSE,out.width = '100%'}
print(p2)
```


Table 1 shows the most recent 5 year mean pHOS estimates for all methods for each population and the two sub-populations.
```{r table 1, message=FALSE, warning=FALSE, results="show", echo=FALSE}
Table1
```

## Discussion

## Appendix
Appendix 1: weighting sub-population estimates to obtain total pHOS estimates

```{r appendix table 1, message=FALSE, warning=FALSE, results="show", echo=FALSE}
AppendixTable1
```

```{r appendix table 2, message=FALSE, warning=FALSE, results="show", echo=FALSE}
AppendixTable2
```

Appendix 2: The raw data and annual pHOS estimates for each method for both winter steelhead based on spawning ground surveys, and summer steelhead based on snorkel surveys:
```{r appendix table 3, message=FALSE, warning=FALSE, results="show", echo=FALSE}
AppendixTable3
```

Appendix 3: STAN code used to fit the multivariate state space random walk with logit link using a binomial response to the HOS and NOS data from each population to estimate pHOS.
```{r appendix code, message=FALSE, warning=FALSE, results="show", echo=FALSE}
noquote(read_lines(here::here("code/binomial_ss_random_walk_model_mv.stan")))
```